\input{permve-ntnu-latex-assignment.tex}

\title{	
\normalfont \normalsize 
\textsc{Norwegian University of Science and Technology\\TDT4171 -- Artificial Intelligence Methods} \\ [25pt]
\horrule{0.5pt} \\[0.4cm]
\huge Assignment 1 \\
\horrule{2pt} \\[0.5cm]
}

\author{Per Magnus Veierland\\permve@stud.ntnu.no}

\date{\normalsize\today}

\usepackage{nicefrac}
\usepackage{dot2texi}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

\newacro{CPT}{Conditional Probability Table}

\hyphenation{ContainsPrize}
\hyphenation{MyChoice}
\hyphenation{OpenedByOfficial}

\begin{document}
\maketitle

\section{Counting and basic laws of probability}

\subsection{5-card Poker Hands}

\textit{Consider the domain of dealing 5-card poker hands from a standard deck of 52 cards, under the assumption that the dealer is fair.}

\begin{enumerate}[label=\alph*)]
\item \textit{How many atomic events are there in the joint probability distribution\\(i.e., how many 5-card hands are there)?}\\
The number of 5-card hands in poker can be found with combinatorics by noting that the ordering of the cards does not matter:
\begin{equation}
\binom{52}{5} =
\frac{52!}{5!(52 - 5)!} =
\frac{52 \cdot 51 \cdot 50 \cdot 49 \cdot 48}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} =
\frac{311875200}{120} =
2598960
\end{equation}
\item \textit{What is the probability of each atomic event?}\\
The probability of each atomic event, i.e. the probability of any distinct poker hand, is:
\begin{equation}
\frac{1}{2598960} \approx 3.84769 \cdot 10^{-7}
\end{equation}
\item
\begin{itemize}
\item \textit{What is the probability of being dealt a royal straight flush?}\\
A royal straight flush consists of five cards of the same suit in a consecutive sequence, where the top card is an ace. There are four possible royal straight flush hands; one for each suit. The probability of being dealt a royal straight flush is:
\begin{equation}
\frac{4}{2598960} = \frac{1}{649740} \approx 1.53908 \cdot 10^{-6}
\end{equation}
\item \textit{What is the probability of being dealt four of a kind?}\\
Four of a kind is a poker hand where four of the cards have the same rank, and the fifth card can be any other rank and suit. The number of possible four of a kind hands is the number of ranks; 13, multiplied by the number of possible fifth cards; which is any of the twelve remaining ranks from one of four suits:
\begin{equation}
\frac{13 \cdot 12 \cdot 4}{2598960} = \frac{1}{4165} \approx 2.40096 \cdot 10^{-4}
\end{equation}
\end{itemize}
\end{enumerate}

\subsection{Two cards in a deck}

\textit{Two cards are randomly selected from a deck of 52 playing cards.}

\begin{enumerate}[label=\alph*)]
\item \textit{What is the probability they constitute a pair (that is, that they are the same denomination)?}\\
The number of pairs in a deck of 52 playing cards is given by the number of ranks times the number of ways to form a pair from four suits within a rank:
\begin{equation}
\label{eq:number_of_pairs}
13 \cdot \binom{4}{2} =
13 \cdot \frac{4!}{2!(4 - 2)!} =
13 \cdot \frac{4 \cdot 3}{2} =
13 \cdot \frac{12}{2} =
78
\end{equation}
The number of ways to draw two cards from a deck of 52 playing cards is given by:
\begin{equation}
\binom{52}{2} =
\frac{52!}{2!(52 - 2)!} =
\frac{52 \cdot 51}{2} =
1326
\end{equation}
The probability that drawing two cards from a deck of 52 playing cards yields a pair is given by the number of pairs in a deck, divided by the number of ways to draw two cards from a deck:
\begin{equation}
\frac{78}{1326} = \frac{1}{17} \approx 0.05882
\end{equation}
The solution can also be found by reasoning that the probability of the second card drawn will be of the same rank as the first card drawn is given by:
\begin{equation}
\frac{4 - 1}{52 - 1} = \frac{3}{51} = \frac{1}{17} \approx 0.05882
\end{equation}
\item \textit{What is the conditional probability they constitute a pair given that they are of different suits?}\\
The number of ways to draw two cards of different suits from a deck is given by the number of ways to draw two cards from a deck, minus the number of suits times the number of ways to draw two cards from the same suit:
\begin{equation}
\binom{52}{2} - 4 \cdot \binom{13}{2} =
\frac{52!}{2!(52 - 2)!} - 4 \cdot \frac{13!}{2!(13 - 2)!} =
\frac{52 \cdot 51}{2} - 4 \cdot \frac{13 \cdot 12}{2} =
1326 - 312 =
1014
\end{equation}
The number of possible pairs is given by equation~\ref{eq:number_of_pairs}. The number of ways to draw a suit from a deck, given that the cards drawn will be from different suits, is given by:
\begin{equation}
\frac{78}{1014} = \frac{1}{13} \approx 0.07692
\end{equation}
The solution can also be found by reasoning that the probability of the second card drawn will be the same rank as the first card drawn, given that the second card drawn will be from a different suit, is given by:
\begin{equation}
\frac{4 - 1}{52 - 13} = \frac{3}{39} = \frac{1}{13} \approx 0.07692
\end{equation}
\end{enumerate}

\subsection{Conditional probability}

\textit{If the occurrence of B makes A more likely, does the occurrence of A make B more likely? Why?}\vspace{0.1cm}
We begin with the knowledge that the occurrence of B makes A more likely:

\begin{equation}
\label{eq:a_given_b_more_likely_than_a}
P(A \vert B) > P(A)
\end{equation}

The \textbf{product rule} states that:

\begin{equation}
P(A \land B) = P(A \vert B) \cdot P(B)
\qquad\text{and}\qquad
P(A \land B) = P(B \vert A) \cdot P(A)
\end{equation}

Equating the two right-hand sides and dividing by $P(B)$ gives us \textbf{Bayes' rule}:

\begin{equation}
\label{eq:bayes}
P(A \vert B) = \frac{P(B \vert A) \cdot P(A)}{P(B)}
\end{equation}

Replacing the left-hand side of the known inequality from equation~\ref{eq:a_given_b_more_likely_than_a} with the right-hand side of equation~\ref{eq:bayes} gives us the inequality:

\begin{equation}
\frac{P(B \vert A) \cdot P(A)}{P(B)} > P(A)
\end{equation}

Multiplying both sides by $P(B)$:

\begin{equation}
P(B \vert A) \cdot P(A) > P(A) \cdot P(B)
\end{equation}

Dividing both sides by $P(A)$:

\begin{equation}
\label{eq:b_given_a_more_likely_than_b}
P(B \vert A) > P(B)
\end{equation}

\setlength\parindent{17pt}
This derivation shows that if it is known that the probability of A given B is greater than the prior probability of A (equation~\ref{eq:a_given_b_more_likely_than_a}), it is also true that the probability of B given A is greater than the prior probability of B (equation~\ref{eq:b_given_a_more_likely_than_b}).

Intuitively this makes sense, since knowledge that a cause is more probable given the presence of a symptom would also make the probability of the symptom more likely given the presence of the cause.
\setlength\parindent{0pt}

\section{Bayesian Network Construction}

\begin{figure}
\centering
\begin{dot2tex}[dot, scale=0.6]
digraph G {
node [shape=ellipse];

illness_current     [label="Illness at the moment"]
illness_history     [label="History of illness"]
number_of_children  [label="Number of children"]
working_parents     [label="Working parents"]
religion            [label="Religion"]
household_income    [label="Household income"]
fish_eating_habits  [label="Fish-eating habits"]
fiber_eating_habits [label="Fiber-eating habits"]
drinking_habits     [label="Drinking habits"]

illness_history     -> illness_current;
number_of_children  -> illness_history;
working_parents     -> household_income;
religion            -> number_of_children;
religion            -> working_parents;
religion            -> household_income;
religion            -> fish_eating_habits;
religion            -> drinking_habits;
household_income    -> drinking_habits;
household_income    -> fish_eating_habits;
household_income    -> fiber_eating_habits;
household_income    -> number_of_children;
fish_eating_habits  -> illness_history;
fiber_eating_habits -> illness_history;
drinking_habits     -> illness_history;
}
\end{dot2tex}
\label{fig:p2_bayesian_network}
\caption{Bayesian network showing causal links between random variables in problem II.}
\end{figure}

\setlength\parindent{17pt}
Figure~\ref{fig:p2_bayesian_network} shows a Bayesian network for the random variables
\begin{inparaenum}[1)]
\item \textit{Illness at the moment},
\item \textit{History of illness},
\item \textit{Number of children},
\item \textit{Working parents},
\item \textit{Religion},
\item \textit{Household income},
\item \textit{Fish-eating habits},
\item \textit{Fiber-eating habits}, and
\item \textit{Drinking habits}
\end{inparaenum}.

Modeling the network based on causality leads to specifying fewer conditional probability values, as well as the values being easier to find since they are more intuitive.

The conditional independence properties of the network is as follows:
\setlength\parindent{0pt}

\begin{enumerate}
\item \textit{Illness at the moment} is conditionally independent of all other random variables, given its parent \textit{History of illness}.

\item \textit{History of illness} is conditionally independent of \textit{Household income}, \textit{Working parents}, and \textit{Religion} -- given \textit{Number of children}, \textit{Fiber-eating habits}, \textit{Fish-eating habits}, and \textit{Drinking habits}.

\item \textit{Number of children} is conditionally independent of \textit{Working parents}, \textit{Fiber-eating habits}, \textit{Fish-eating habits}, and \textit{Drinking habits} -- given its parents \textit{Religion} and \textit{Household income}. Two causal relationships which are poorly modeled is the relationship with \textit{History of illness} and the relationship with \textit{Working parents}. The model shows that \textit{Number of children} causally affects \textit{History of illness}, but it does not show that \textit{History of illness} may causally affect \textit{Number of children} as well. The model shows that \textit{Working parents} indirectly causally affects \textit{Number of children} through \textit{Household income}, but it does not show that \textit{Number of children} may causally affect \textit{Working parents}.

\item \textit{Working parents} is conditionally independent of \textit{Number of children}, \textit{Fiber-eating habits}, \textit{Fish-eating habits}, \textit{Drinking habits}, \textit{History of illness}, and \textit{Illness at the moment} -- given its parent \textit{Religion} and its child \textit{Household income}. Not causally modeled is how \textit{Illness at the moment} may affect \textit{Working parents}.

\item \textit{Religion} is conditionally independent of \textit{Fiber-eating habits}, \textit{History of illness}, and \textit{Illness at the moment} -- given its children \textit{Number of children}, \textit{Household income}, \textit{Working parents}, \textit{Fish-eating habits}, and \textit{Drinking habits}. Not causally modeled is how \textit{History of illness} may affect \textit{Religion}, i.e. not ``mental health issues'' -- but how religion may serve as a coping mechanism for serious illnesses.

\item \textit{Household income} is conditionally independent of \textit{History of illness} and \textit{Illness at the moment} -- given its parents \textit{Religion} and \textit{Working parents}, and its children \textit{Number of children}, \textit{Fiber-eating habits}, \textit{Fish-eating habits}, and \textit{Drinking habits}.

\item \textit{Fish-eating habits} is conditionally independent of \textit{Working parents} and \textit{Illness at the moment} -- given its parents \textit{Religion} and \textit{Household income}, and its child \textit{History of illness}, and the parents of its child; \textit{Number of children}, \textit{Fiber-eating habits} and \textit{Drinking habits}.

\item \textit{Fiber-eating habits} is conditionally independent of \textit{Religion}, \textit{Working parents}, and \textit{Illness at the moment} -- given its parent \textit{Household income}, its children \textit{History of illness}, and the parents of its child; \textit{Number of children}, \textit{Fish-eating habits}, and \textit{Drinking habits}.

\item \textit{Drinking habits} is conditionally independent of \textit{Working parents} and \textit{Illness at the moment} -- given its parents \textit{Religion} and \textit{Household income}, its children \textit{History of illness}, and the parents of its child; \textit{Number of children}, \textit{Fiber-eating habits} and \textit{Fish-eating habits}.

\end{enumerate}

\newpage

\section{Bayesian Network Application}

\setlength\parindent{17pt}

\begin{figure}
\centering
\begin{dot2tex}[dot, scale=0.6]
digraph G {
node [shape=ellipse];

my_choice          [label="MyChoice (M)"]
contains_prize     [label="ContainsPrize (C)"]
opened_by_official [label="OpenedByOfficial (O)"]

my_choice          -> opened_by_official;
contains_prize     -> opened_by_official;
}
\end{dot2tex}
\label{fig:p3_bayesian_network}
\caption{Bayesian network modeling problem III.}
\end{figure}

\begin{sloppypar}
The described scenario is shown modeled in Figure~2 as a Bayesian network with three random variables; \textit{ContainsPrize}~(C), \textit{MyChoice}~(M), and \textit{OpenedByOfficial}~(O). In the game, the action made by the official is a direct consequence of the player's chosen door and the prize door. This makes it intuitive to model the network with \textit{OpenedByOfficial} being caused by \textit{MyChoice} and \textit{ContainsPrize}.
\end{sloppypar}

\begin{table}
\centering
\begin{tabular}{ccccc}
\toprule
$C$ & $M$ & $P(O=a \vert C, M)$ & $P(O=b \vert C, M)$ & $P(O=c \vert C, M)$ \\
\midrule
a   & a   & 0                   & $\nicefrac{1}{2}$   & $\nicefrac{1}{2}$   \\
a   & b   & 0                   & 0                   & 1                   \\
a   & c   & 0                   & 1                   & 0                   \\
b   & a   & 0                   & 0                   & 1                   \\
b   & b   & $\nicefrac{1}{2}$   & 0                   & $\nicefrac{1}{2}$   \\
b   & c   & 1                   & 0                   & 0                   \\
c   & a   & 0                   & 1                   & 0                   \\
c   & b   & 1                   & 0                   & 0                   \\
c   & c   & $\nicefrac{1}{2}$   & $\nicefrac{1}{2}$   & 0                   \\
\bottomrule
\end{tabular}
\label{table:p3_o_cpt}
\caption{\acf{CPT} for $\textbf{P}(O \vert C, M)$.}
\end{table}

\begin{sloppypar}
The prior probability of \textit{MyChoice} is $\textbf{P}(M) = \langle \nicefrac{1}{3}, \nicefrac{1}{3}, \nicefrac{1}{3} \rangle$, and the prior probability of \textit{ContainsPrize} is $\textbf{P}(C) = \langle \nicefrac{1}{3}, \nicefrac{1}{3}, \nicefrac{1}{3} \rangle$. Table~1 shows the \ac{CPT} for the random variable \textit{OpenedByOfficial}.
\end{sloppypar}

\begin{sloppypar}
Shown in Equation~\ref{eq:p3_o_choose_b} is the scenario where the player chooses door~$a$ and the official chooses door~$b$. This results in $\textbf{P}(C \vert M=a \land O=b) = \langle \nicefrac{1}{3}, 0, \nicefrac{2}{3} \rangle$. Interpreting this result shows that there is a $\nicefrac{1}{3}$ chance that the originally chosen door is the prize door, that there is zero chance that the door chosen by the official is the prize door, and that there is a $\nicefrac{2}{3}$ chance that door~$c$ is the prize door.
\end{sloppypar}

\begin{equation}
\begin{split}
\textbf{P}(C \vert M=a \land O=b)
&= \alpha \cdot \textbf{P}(C) \cdot \textbf{P}(M=a) \cdot \textbf{P}(O=b \vert M=a, C) \\
&= \alpha \cdot \langle \frac{1}{3}, \frac{1}{3}, \frac{1}{3} \rangle \cdot \frac{1}{3} \cdot \langle \frac{1}{2}, 0, 1 \rangle \\
&= \alpha \cdot \langle \frac{1}{18}, 0, \frac{1}{9} \rangle \\
&= \langle \frac{1}{3}, 0, \frac{2}{3} \rangle
\end{split}
\label{eq:p3_o_choose_b}
\end{equation}

Equation~\ref{eq:p3_o_choose_c} shows the symmetric scenario where the player chooses door~$a$ and the official chooses door~$c$. This results in $\textbf{P}(C \vert M=a \land O=c) = \langle \nicefrac{1}{3}, \nicefrac{2}{3}, 0 \rangle$. Interpreting this result shows that there is a $\nicefrac{1}{3}$ chance that the originally chosen door is the prize door, that there is a $\nicefrac{2}{3}$ chance that door~$b$ is the prize door, and that there zero chance that the door chosen by the official is the prize door.

\begin{equation}
\begin{split}
\textbf{P}(C \vert M=a \land O=c)
&= \alpha \cdot \textbf{P}(C) \cdot P(M=a) \cdot \textbf{P}(O=c \vert M=a, C) \\
&= \alpha \cdot \langle \frac{1}{3}, \frac{1}{3}, \frac{1}{3} \rangle \cdot \frac{1}{3} \cdot \langle \frac{1}{2}, 1, 0 \rangle \\
&= \alpha \cdot \langle \frac{1}{18}, \frac{1}{9}, 0 \rangle \\
&= \langle \frac{1}{3}, \frac{2}{3}, 0 \rangle
\end{split}
\label{eq:p3_o_choose_c}
\end{equation}

Based on Equation~\ref{eq:p3_o_choose_b} and Equation~\ref{eq:p3_o_choose_c} it can be concluded that given the knowledge of which door the player picked, and which door the official opened; there is a posterior probability of $\nicefrac{1}{3}$ that the door picked by the player is the prize door, and a posterior probability of $\nicefrac{2}{3}$ that the door picked by the player is not the prize door. This means that the best strategy for the player will always be to change doors after the official opens one door; since this will double his chances of winning the prize!

\end{document}

